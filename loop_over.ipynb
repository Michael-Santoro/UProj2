{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d19e50ca-92c9-4526-9c78-b3947f9fd5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "## Imports\n",
    "\n",
    "## general package imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "## Add current working directory to path\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "## Waymo open dataset reader\n",
    "from tools.waymo_reader.simple_waymo_open_dataset_reader import utils as waymo_utils\n",
    "from tools.waymo_reader.simple_waymo_open_dataset_reader import WaymoDataFileReader, dataset_pb2, label_pb2\n",
    "\n",
    "## 3d object detection\n",
    "import student.objdet_pcl as pcl\n",
    "import student.objdet_detect as det\n",
    "import student.objdet_eval as eval\n",
    "\n",
    "import misc.objdet_tools as tools \n",
    "from misc.helpers import save_object_to_file, load_object_from_file, make_exec_list\n",
    "\n",
    "## Tracking\n",
    "from student.filter import Filter\n",
    "from student.trackmanagement import Trackmanagement\n",
    "from student.association import Association\n",
    "from student.measurements import Sensor, Measurement\n",
    "from misc.evaluation import plot_tracks, plot_rmse, make_movie\n",
    "import misc.params as params \n",
    " \n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30b892f-bdb5-4275-925a-fc8f040d0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "## Set parameters and perform initializations\n",
    "\n",
    "## Select Waymo Open Dataset file and frame numbers\n",
    "data_filename = 'training_segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord' # Sequence 1\n",
    "# data_filename = 'training_segment-10072231702153043603_5725_000_5745_000_with_camera_labels.tfrecord' # Sequence 2\n",
    "#data_filename = 'training_segment-10963653239323173269_1924_000_1944_000_with_camera_labels.tfrecord' # Sequence 3\n",
    "show_only_frames = [0, 1] # show only frames in interval for debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5220adc-4e5b-4109-99af-d9dbdb0b80ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using darknet\n",
      "Loaded weights from /home/UProj2/tools/objdet_models/darknet/pretrained/complex_yolov4_mse_loss.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Prepare Waymo Open Dataset file for loading\n",
    "data_fullpath = os.path.join(os.path.abspath(''), 'dataset', data_filename) # adjustable path in case this script is called from another working directory\n",
    "results_fullpath = os.path.join(os.path.abspath(''), 'results')\n",
    "datafile = WaymoDataFileReader(data_fullpath)\n",
    "datafile_iter = iter(datafile)  # initialize dataset iterator\n",
    "\n",
    "## Initialize object detection\n",
    "configs_det = det.load_configs(model_name='darknet') # options are 'darknet', 'fpn_resnet'\n",
    "model_det = det.create_model(configs_det)\n",
    "\n",
    "configs_det.use_labels_as_objects = False # True = use groundtruth labels as objects, False = use model-based detection\n",
    "\n",
    "## Uncomment this setting to restrict the y-range in the final project\n",
    "# configs_det.lim_y = [-25, 25] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ed7539-82e8-4821-8e18-236708aaba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize tracking\n",
    "KF = Filter() # set up Kalman filter \n",
    "association = Association() # init data association\n",
    "manager = Trackmanagement() # init track manager\n",
    "lidar = None # init lidar sensor object\n",
    "camera = None # init camera sensor object\n",
    "np.random.seed(10) # make random values predictable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e9c8204-4dce-46ab-8cb8-e8e1935e9b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selective execution and visualization\n",
    "exec_detection = [] # options are 'bev_from_pcl', 'detect_objects', 'validate_object_labels', 'measure_detection_performance'; options not in the list will be loaded from file\n",
    "exec_tracking = [] # options are 'perform_tracking'\n",
    "exec_visualization = ['sow_pcl'] # options are 'show_range_image', 'show_bev', 'show_pcl', 'show_labels_in_image', 'show_objects_and_labels_in_bev', 'show_objects_in_bev_labels_in_camera', 'show_tracks', 'show_detection_performance', 'make_tracking_movie'\n",
    "exec_list = make_exec_list(exec_detection, exec_tracking, exec_visualization)\n",
    "vis_pause_time = 0 # set pause time between frames in ms (0 = stop between frames until key is pressed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854bef18-172f-4067-9546-e451d7f4b226",
   "metadata": {},
   "source": [
    "# ID_S1_EX1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395f7cd6-509e-4236-8f87-fd89c60e4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = next(datafile_iter)\n",
    "lidar_name = dataset_pb2.LaserName.TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9fda024-1859-4931-931e-67687b84173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e1ad96-00b0-4e53-8658-f9b859c94897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student task ID_S1_EX1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2790/2037536016.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_range_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlidar_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'range_image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_pause_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "img_range = pcl.show_range_image(frame, lidar_name)\n",
    "img_range = img_range.astype(np.uint8)\n",
    "cv2.imshow('range_image', img_range)\n",
    "cv2.waitKey(vis_pause_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd19fd-7a9c-463d-a6ef-0e7f1b0d9a34",
   "metadata": {},
   "source": [
    "## Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc4d173a-4a16-4392-9319-795676d750b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidar_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eee39b95-b5fc-47b2-a56f-a1f655ad99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 : extract lidar data and range image for the roof-mounted lidar\n",
    "lidar = [obj for obj in frame.lasers if obj.name == lidar_name][0]\n",
    "ri = []\n",
    "if len(lidar.ri_return1.range_image_compressed) > 0: # use first response\n",
    "    ri = dataset_pb2.MatrixFloat()\n",
    "    ri.ParseFromString(zlib.decompress(lidar.ri_return1.range_image_compressed))\n",
    "    ri = np.array(ri.data).reshape(ri.shape.dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef3e583a-8e1e-4d29-b5f5-4d34cb11da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 : extract the range and the intensity channel from the range image\n",
    "ri_range = ri[:,:,0]\n",
    "ri_intensity = ri[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec8ab396-d892-4a77-b6a3-01d243a5be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 : set values <0 to zero\n",
    "ri_range[ri_range<0]=0.0\n",
    "ri_intensity[ri_intensity<0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70be4acf-ceb5-433d-a3c0-27f685e0f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 : map the range channel onto an 8-bit scale and make sure that the full range of values is appropriately considered\n",
    "ri_range = ri_range * 255 / (np.amax(ri_range) - np.amin(ri_range))\n",
    "ri_intensity = np.amax(ri_intensity)/2 * ri_intensity * 255 / (np.amax(ri_intensity) - np.amin(ri_intensity)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddc94b4e-d9aa-44ce-a829-f2fc7a50d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5 : map the intensity channel onto an 8-bit scale and normalize with the difference between the 1- and 99-percentile to mitigate the influence of outliers\n",
    "img_range = ri_range.astype(np.uint8)\n",
    "img_intensity = ri_intensity.astype(np.uint8)\n",
    "\n",
    "img_range = (img_range - np.percentile(img_range, 1))/(np.percentile(img_range, 99)-np.percentile(img_range, 1))\n",
    "img_intensity = (img_intensity - np.percentile(img_intensity, 1))/(np.percentile(img_intensity, 99)-np.percentile(img_intensity, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3feaad97-4e3d-46d7-a307-d9c5608ab123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 6 : stack the range and intensity image vertically using np.vstack and convert the result to an unsigned 8-bit integer\n",
    "img_range_intensity = np.vstack((img_range,img_intensity))\n",
    "img_range_intensity.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5281b3b-9ae0-428c-b7e1-0c9157780db2",
   "metadata": {},
   "source": [
    "# ID_S1_EX2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "516f3037-0c74-46fe-8ed9-360179df2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_frame = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ae4f84-b1f0-4bc4-8014-11a267b67679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/UProj2/results'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_fullpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6fb749a-b8db-4c65-ae3d-ea4a91e95667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading lidar point-cloud from result file\n"
     ]
    }
   ],
   "source": [
    "print('loading lidar point-cloud from result file')\n",
    "lidar_pcl = load_object_from_file(results_fullpath, data_filename, 'lidar_pcl', cnt_frame)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28169c87-e74c-4f0d-a5b1-6f674314fbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student task ID_S1_EX2\n",
      "VisualizerWithKeyCallback with name show_pcl\n",
      "VisualizerWithKeyCallback with name show_pcl\n",
      "VisualizerWithKeyCallback with name show_pcl\n",
      "VisualizerWithKeyCallback with name show_pcl\n",
      "VisualizerWithKeyCallback with name show_pcl\n",
      "VisualizerWithKeyCallback with name show_pcl\n",
      "VisualizerWithKeyCallback with name show_pcl\n",
      "VisualizerWithKeyCallback with name show_pcl\n",
      "VisualizerWithKeyCallback with name show_pcl\n",
      "VisualizerWithKeyCallback with name show_pcl\n",
      "VisualizerWithKeyCallback with name show_pcl\n",
      "VisualizerWithKeyCallback with name show_pcl\n"
     ]
    }
   ],
   "source": [
    "pcl.show_pcl(lidar_pcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0862fcbd-39e2-47ed-81b6-3b58e61d8419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(os.path.abspath(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bdb609-152c-4e90-8dc0-e5e3b3d2c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "## Perform detection & tracking over all selected frames\n",
    "\n",
    "cnt_frame = 0 \n",
    "all_labels = []\n",
    "det_performance_all = [] \n",
    "np.random.seed(0) # make random values predictable\n",
    "if 'show_tracks' in exec_list:    \n",
    "    fig, (ax2, ax) = plt.subplots(1,2) # init track plot\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        ## Get next frame from Waymo dataset\n",
    "        frame = next(datafile_iter)\n",
    "        if cnt_frame < show_only_frames[0]:\n",
    "            cnt_frame = cnt_frame + 1\n",
    "            continue\n",
    "        elif cnt_frame > show_only_frames[1]:\n",
    "            print('reached end of selected frames')\n",
    "            break\n",
    "        \n",
    "        print('------------------------------')\n",
    "        print('processing frame #' + str(cnt_frame))\n",
    "\n",
    "        #################################\n",
    "        ## Perform 3D object detection\n",
    "\n",
    "        ## Extract calibration data and front camera image from frame\n",
    "        lidar_name = dataset_pb2.LaserName.TOP\n",
    "        camera_name = dataset_pb2.CameraName.FRONT\n",
    "        lidar_calibration = waymo_utils.get(frame.context.laser_calibrations, lidar_name)        \n",
    "        camera_calibration = waymo_utils.get(frame.context.camera_calibrations, camera_name)\n",
    "        if 'load_image' in exec_list:\n",
    "            image = tools.extract_front_camera_image(frame) \n",
    "\n",
    "        ## Compute lidar point-cloud from range image    \n",
    "        if 'pcl_from_rangeimage' in exec_list:\n",
    "            print('computing point-cloud from lidar range image')\n",
    "            lidar_pcl = tools.pcl_from_range_image(frame, lidar_name)\n",
    "        else:\n",
    "            print('loading lidar point-cloud from result file')\n",
    "            lidar_pcl = load_object_from_file(results_fullpath, data_filename, 'lidar_pcl', cnt_frame)\n",
    "            \n",
    "        ## Compute lidar birds-eye view (bev)\n",
    "        if 'bev_from_pcl' in exec_list:\n",
    "            print('computing birds-eye view from lidar pointcloud')\n",
    "            lidar_bev = pcl.bev_from_pcl(lidar_pcl, configs_det)\n",
    "        else:\n",
    "            print('loading birds-eve view from result file')\n",
    "            lidar_bev = load_object_from_file(results_fullpath, data_filename, 'lidar_bev', cnt_frame)\n",
    "\n",
    "        ## 3D object detection\n",
    "        if (configs_det.use_labels_as_objects==True):\n",
    "            print('using groundtruth labels as objects')\n",
    "            detections = tools.convert_labels_into_objects(frame.laser_labels, configs_det)\n",
    "        else:\n",
    "            if 'detect_objects' in exec_list:\n",
    "                print('detecting objects in lidar pointcloud')   \n",
    "                detections = det.detect_objects(lidar_bev, model_det, configs_det)\n",
    "            else:\n",
    "                print('loading detected objects from result file')\n",
    "                # load different data for final project vs. mid-term project\n",
    "                if 'perform_tracking' in exec_list:\n",
    "                    detections = load_object_from_file(results_fullpath, data_filename, 'detections', cnt_frame)\n",
    "                else:\n",
    "                    detections = load_object_from_file(results_fullpath, data_filename, 'detections_' + configs_det.arch + '_' + str(configs_det.conf_thresh), cnt_frame)\n",
    "\n",
    "        ## Validate object labels\n",
    "        if 'validate_object_labels' in exec_list:\n",
    "            print(\"validating object labels\")\n",
    "            valid_label_flags = tools.validate_object_labels(frame.laser_labels, lidar_pcl, configs_det, 0 if configs_det.use_labels_as_objects==True else 10)\n",
    "        else:\n",
    "            print('loading object labels and validation from result file')\n",
    "            valid_label_flags = load_object_from_file(results_fullpath, data_filename, 'valid_labels', cnt_frame)            \n",
    "\n",
    "        ## Performance evaluation for object detection\n",
    "        if 'measure_detection_performance' in exec_list:\n",
    "            print('measuring detection performance')\n",
    "            det_performance = eval.measure_detection_performance(detections, frame.laser_labels, valid_label_flags, configs_det.min_iou)     \n",
    "        else:\n",
    "            print('loading detection performance measures from file')\n",
    "            # load different data for final project vs. mid-term project\n",
    "            if 'perform_tracking' in exec_list:\n",
    "                det_performance = load_object_from_file(results_fullpath, data_filename, 'det_performance', cnt_frame)\n",
    "            else:\n",
    "                det_performance = load_object_from_file(results_fullpath, data_filename, 'det_performance_' + configs_det.arch + '_' + str(configs_det.conf_thresh), cnt_frame)   \n",
    "\n",
    "        det_performance_all.append(det_performance) # store all evaluation results in a list for performance assessment at the end\n",
    "        \n",
    "\n",
    "        ## Visualization for object detection\n",
    "        if 'show_range_image' in exec_list:\n",
    "            img_range = pcl.show_range_image(frame, lidar_name)\n",
    "            img_range = img_range.astype(np.uint8)\n",
    "            cv2.imshow('range_image', img_range)\n",
    "            cv2.waitKey(vis_pause_time)\n",
    "\n",
    "        if 'show_pcl' in exec_list:\n",
    "            pcl.show_pcl(lidar_pcl)\n",
    "\n",
    "        if 'show_bev' in exec_list:\n",
    "            tools.show_bev(lidar_bev, configs_det)  \n",
    "            cv2.waitKey(vis_pause_time)          \n",
    "\n",
    "        if 'show_labels_in_image' in exec_list:\n",
    "            img_labels = tools.project_labels_into_camera(camera_calibration, image, frame.laser_labels, valid_label_flags, 0.5)\n",
    "            cv2.imshow('img_labels', img_labels)\n",
    "            cv2.waitKey(vis_pause_time)\n",
    "\n",
    "        if 'show_objects_and_labels_in_bev' in exec_list:\n",
    "            tools.show_objects_labels_in_bev(detections, frame.laser_labels, lidar_bev, configs_det)\n",
    "            cv2.waitKey(vis_pause_time)         \n",
    "\n",
    "        if 'show_objects_in_bev_labels_in_camera' in exec_list:\n",
    "            tools.show_objects_in_bev_labels_in_camera(detections, lidar_bev, image, frame.laser_labels, valid_label_flags, camera_calibration, configs_det)\n",
    "            cv2.waitKey(vis_pause_time)               \n",
    "\n",
    "\n",
    "        #################################\n",
    "        ## Perform tracking\n",
    "        if 'perform_tracking' in exec_list:\n",
    "            # set up sensor objects\n",
    "            if lidar is None:\n",
    "                lidar = Sensor('lidar', lidar_calibration)\n",
    "            if camera is None:\n",
    "                camera = Sensor('camera', camera_calibration)\n",
    "            \n",
    "            # preprocess lidar detections\n",
    "            meas_list_lidar = []\n",
    "            for detection in detections:\n",
    "                # check if measurement lies inside specified range\n",
    "                if detection[1] > configs_det.lim_x[0] and detection[1] < configs_det.lim_x[1] and detection[2] > configs_det.lim_y[0] and detection[2] < configs_det.lim_y[1]:\n",
    "                    meas_list_lidar = lidar.generate_measurement(cnt_frame, detection[1:], meas_list_lidar)\n",
    "\n",
    "            # preprocess camera detections\n",
    "            meas_list_cam = []\n",
    "            for label in frame.camera_labels[0].labels:\n",
    "                if(label.type == label_pb2.Label.Type.TYPE_VEHICLE):\n",
    "                \n",
    "                    box = label.box\n",
    "                    # use camera labels as measurements and add some random noise\n",
    "                    z = [box.center_x, box.center_y, box.width, box.length]\n",
    "                    z[0] = z[0] + np.random.normal(0, params.sigma_cam_i) \n",
    "                    z[1] = z[1] + np.random.normal(0, params.sigma_cam_j)\n",
    "                    meas_list_cam = camera.generate_measurement(cnt_frame, z, meas_list_cam)\n",
    "            \n",
    "            # Kalman prediction\n",
    "            for track in manager.track_list:\n",
    "                print('predict track', track.id)\n",
    "                KF.predict(track)\n",
    "                track.set_t((cnt_frame - 1)*0.1) # save next timestamp\n",
    "                \n",
    "            # associate all lidar measurements to all tracks\n",
    "            association.associate_and_update(manager, meas_list_lidar, KF)\n",
    "            \n",
    "            # associate all camera measurements to all tracks\n",
    "            association.associate_and_update(manager, meas_list_cam, KF)\n",
    "            \n",
    "            # save results for evaluation\n",
    "            result_dict = {}\n",
    "            for track in manager.track_list:\n",
    "                result_dict[track.id] = track\n",
    "            manager.result_list.append(copy.deepcopy(result_dict))\n",
    "            label_list = [frame.laser_labels, valid_label_flags]\n",
    "            all_labels.append(label_list)\n",
    "            \n",
    "            # visualization\n",
    "            if 'show_tracks' in exec_list:\n",
    "                fig, ax, ax2 = plot_tracks(fig, ax, ax2, manager.track_list, meas_list_lidar, frame.laser_labels, \n",
    "                                        valid_label_flags, image, camera, configs_det)\n",
    "                if 'make_tracking_movie' in exec_list:\n",
    "                    # save track plots to file\n",
    "                    fname = results_fullpath + '/tracking%03d.png' % cnt_frame\n",
    "                    print('Saving frame', fname)\n",
    "                    fig.savefig(fname)\n",
    "\n",
    "        # increment frame counter\n",
    "        cnt_frame = cnt_frame + 1    \n",
    "\n",
    "    except StopIteration:\n",
    "        # if StopIteration is raised, break from loop\n",
    "        print(\"StopIteration has been raised\\n\")\n",
    "        break\n",
    "\n",
    "\n",
    "#################################\n",
    "## Post-processing\n",
    "\n",
    "## Evaluate object detection performance\n",
    "if 'show_detection_performance' in exec_list:\n",
    "    eval.compute_performance_stats(det_performance_all, configs_det)\n",
    "\n",
    "## Plot RMSE for all tracks\n",
    "if 'show_tracks' in exec_list:\n",
    "    plot_rmse(manager, all_labels, configs_det)\n",
    "\n",
    "## Make movie from tracking results    \n",
    "if 'make_tracking_movie' in exec_list:\n",
    "    make_movie(results_fullpath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
